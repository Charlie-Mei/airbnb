direction = "forward",
trace = F)
test_model <- step(sm,
scope = list(upper = em, lower = sm),
direction = "both",
trace = F)
summary(test_model)
library(glmnet)
X <- model.matrix(price ~ . test[, -1])
names(test)
rm(X)
# Use a test forward stepwise model
sm <- lm(price ~ 1, test)
em <- lm(price ~ ., test)
test_model <- lm(price ~ ., test)
summary(test_model)
test_model <- lm(price ~ zipcode + accommodates + bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_review + review_scores_rating, test)
test_model <- lm(price ~ zipcode + accommodates + bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
test_model <- lm(price ~ zipcode + bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
test_model <- lm(price ~ factor(zipcode) + bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
library(tidyverse)
library(leaps)
library(glmnet)
mydata <- read_csv("Data/analysisData.csv")
locs <- lapply(mydata, is.numeric) %>% unlist()
test <- mydata[, which(locs)]
test_model <- lm(price ~ factor(zipcode) + bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
scoringData = read_csv('Data/scoringData.csv')
pred <- predict(test_model, newdata = scoringData)
submission <- data.frame(id = scoringData$id,
price = pred)
write_csv(submission, "Test_submission.csv")
library(tidyverse)
library(leaps)
library(glmnet)
mydata <- read_csv("Data/analysisData.csv")
locs <- lapply(mydata, is.numeric) %>% unlist()
test <- mydata[, which(locs)]
test_model <- lm(price ~ factor(zipcode) + bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
scoringData = read_csv('Data/scoringData.csv')
pred <- predict(test_model, newdata = scoringData)
submission <- data.frame(id = scoringData$id,
price = pred)
pred <- predict(test_model, newdata = scoringData)
scoringData = read_csv('Data/scoringData.csv')
pred <- predict(test_model, newdata = scoringData)
submission <- data.frame(id = scoringData$id,
price = pred)
View(scoringData)
test_model <- lm(price ~ bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
scoringData = read_csv('Data/scoringData.csv')
pred <- predict(test_model, newdata = scoringData)
submission <- data.frame(id = scoringData$id,
price = pred)
View(test_model)
submission <- data.frame(id = scoringData$id,
price = pred)
write_csv(submission, "Test_submission.csv")
mydata <- read_csv("Data/analysisData.csv")
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F) %>%
tribble()
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F) %>%
as_tibble()
mydata
str(mydata)
locs <- lapply(mydata, is.numeric) %>% unlist()
test <- mydata[, which(locs)]
test_model <- lm(price ~ bathrooms + bedrooms +
beds + square_feet + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
summary(test)
test_model <- lm(price ~ bathrooms + bedrooms +
beds + minimum_nights + maximum_nights +
number_of_reviews + review_scores_rating, test)
summary(test_model)
scoringData = read_csv('Data/scoringData.csv')
pred <- predict(test_model, newdata = scoringData)
submission <- data.frame(id = scoringData$id,
price = pred)
write_csv(submission, "Test_submission.csv")
## Importing packages
library(tidyverse) # metapackage with lots of helpful functions
library(leaps)
library(glmnet)
library(gridExtra)
library(caret)
library(broom)
# Import the data and create and train and test set
mydata <- read.csv("../input/pricelala2/analysisData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
summary(train$price)
# Density plot
p1 <- ggplot(train, aes(price)) +
geom_density(col = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = mean(mydata$price), col = "red") +
labs(title = "Distribution of prices") +
theme_minimal()
# Boxplot to identify outliers
p2 <- ggplot(train, aes(1, price)) +
geom_boxplot(col = "red", fill = "blue", alpha = 0.4) +
theme_minimal()
grid.arrange(p1, p2, ncol = 2)
# Create LB (lower bound) and UB (upper bound) to remove outliers, also remove price = 0
LB <- quantile(train$price, probs = 0.25 ) - 1.5*IQR(train$price)
UB <- quantile(train$price, probs = 0.75) + 1.5*IQR(train$price)
train <- train %>% filter(price >= LB & price <= UB, price != 0)
# Locate our nuerical
locs <- lapply(train, is.numeric) %>% unlist()
ndata <- train[, locs] %>% select(-id, -price, -weekly_price, -monthly_price)
missing_counts <- lapply(ndata, function(x){
sum(is.na(x))
}) %>% unlist()
missing_counts
# mdata is a placeholder atm with just numeric variables with no NAs
mdata <- ndata %>% select(-square_feet, -security_deposit, -cleaning_fee, -reviews_per_month, -contains("listings_count"), -beds,
-contains("maximum_minimum_nights"), -contains("minimum_minimum_nights"), -number_of_reviews_ltm, -contains("0"))
price <- train$price
mdata <- cbind(mdata, price)
str(mdata)
# Forward stepwise model
start_model <- lm(price ~ 1, mdata)
end_model <- lm(price ~ ., mdata)
model <- step(start_model,
scope = list(upper = end_model, lower = start_model),
direction = "forward",
trace = F)
summary(model)
# Lasso model
X <- model.matrix(price ~ ., mdata)
y <- mdata$price
set.seed(1431)
cv.lasso <- cv.glmnet(X, y, alpha = 1)
#plot(cv.lasso)
#coef(cv.lasso)
model2 <- lm(price ~ accommodates + bathrooms + guests_included + minimum_nights +
availability_365 + number_of_reviews + review_scores_rating +
review_scores_cleanliness + review_scores_location + review_scores_value, mdata)
summary(model2)
pred <- predict(model2)
rmse <- mean((train$price - pred)^2) %>% sqrt()
test_pred <- predict(model2, newdata = test)
t_rmse <- mean((test$price - test_pred)^2) %>% sqrt()
paste("Training RMSE:", rmse)
paste("Test RMSE:", t_rmse)
scoring <- read.csv("../input/pricelala2/scoringData.csv", stringsAsFactors = F)
pred <- predict(model, newdata = scoring)
submission <- data.frame(id = scoring$id, price = pred)
write_csv(submission, "../input/pricelala2/submission.csv")
# Import the data and create and train and test set
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
## Importing packages
library(tidyverse) # metapackage with lots of helpful functions
library(leaps)
library(glmnet)
library(gridExtra)
library(caret)
library(broom)
# Import the data and create and train and test set
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
summary(train$price)
# Density plot
p1 <- ggplot(train, aes(price)) +
geom_density(col = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = mean(mydata$price), col = "red") +
labs(title = "Distribution of prices") +
theme_minimal()
# Boxplot to identify outliers
p2 <- ggplot(train, aes(1, price)) +
geom_boxplot(col = "red", fill = "blue", alpha = 0.4) +
theme_minimal()
grid.arrange(p1, p2, ncol = 2)
# Create LB (lower bound) and UB (upper bound) to remove outliers, also remove price = 0
LB <- quantile(train$price, probs = 0.25 ) - 1.5*IQR(train$price)
UB <- quantile(train$price, probs = 0.75) + 1.5*IQR(train$price)
train <- train %>% filter(price >= LB & price <= UB, price != 0)
# Locate our nuerical
locs <- lapply(train, is.numeric) %>% unlist()
ndata <- train[, locs] %>% select(-id, -price, -weekly_price, -monthly_price)
missing_counts <- lapply(ndata, function(x){
sum(is.na(x))
}) %>% unlist()
missing_counts
# mdata is a placeholder atm with just numeric variables with no NAs
mdata <- ndata %>% select(-square_feet, -security_deposit, -cleaning_fee, -reviews_per_month, -contains("listings_count"), -beds,
-contains("maximum_minimum_nights"), -contains("minimum_minimum_nights"), -number_of_reviews_ltm, -contains("0"))
price <- train$price
mdata <- cbind(mdata, price)
str(mdata)
# Forward stepwise model
start_model <- lm(price ~ 1, mdata)
end_model <- lm(price ~ ., mdata)
model <- step(start_model,
scope = list(upper = end_model, lower = start_model),
direction = "forward",
trace = F)
summary(model)
# Lasso model
X <- model.matrix(price ~ ., mdata)
y <- mdata$price
set.seed(1431)
cv.lasso <- cv.glmnet(X, y, alpha = 1)
#plot(cv.lasso)
#coef(cv.lasso)
model2 <- lm(price ~ accommodates + bathrooms + guests_included + minimum_nights +
availability_365 + number_of_reviews + review_scores_rating +
review_scores_cleanliness + review_scores_location + review_scores_value, mdata)
summary(model2)
pred <- predict(model2)
rmse <- mean((train$price - pred)^2) %>% sqrt()
test_pred <- predict(model2, newdata = test)
t_rmse <- mean((test$price - test_pred)^2) %>% sqrt()
paste("Training RMSE:", rmse)
paste("Test RMSE:", t_rmse)
scoring <- read.csv("Data/scoringData.csv", stringsAsFactors = F)
pred <- predict(model, newdata = scoring)
submission <- data.frame(id = scoring$id, price = pred)
write_csv(submission, "submission.csv")
library(tidyverse) # metapackage with lots of helpful functions
library(leaps)
library(glmnet)
library(gridExtra)
library(caret)
library(broom)
# Import the data and create and train and test set
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
scoring <- read.csv("Data/scoringData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
summary(train$price)
# Density plot
p1 <- ggplot(train, aes(price)) +
geom_density(col = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = mean(mydata$price), col = "red") +
labs(title = "Distribution of prices") +
theme_minimal()
# Boxplot to identify outliers
p2 <- ggplot(train, aes(1, price)) +
geom_boxplot(col = "red", fill = "blue", alpha = 0.4) +
theme_minimal()
grid.arrange(p1, p2, ncol = 2)
# Create LB (lower bound) and UB (upper bound) to remove outliers, also remove price = 0
LB <- quantile(train$price, probs = 0.25 ) - 1.5*IQR(train$price)
UB <- quantile(train$price, probs = 0.75) + 1.5*IQR(train$price)
train <- train %>% filter(price >= LB & price <= UB, price != 0)
# Locate numerical data
#locs <- lapply(train, is.numeric) %>% unlist()
#ndata <- train[, locs] %>% select(-id, -price, -weekly_price, -monthly_price)
# Tabularize counts of missingness
tab.missing <- function(df){
locs <- lapply(df, is.numeric) %>% unlist()
ndata <- df[, locs] %>% select(-id, -price, -weekly_price, -monthly_price)
lapply(ndata, function(x){sum(is.na(x))}) %>% unlist()
}
# Filter out missing beds and reviews per month
train <- train %>%
filter(!is.na(beds), !is.na(reviews_per_month), !is.na(host_listings_count), !is.na(host_total_listings_count)) %>%
mutate(security_deposit2 = ifelse(security_deposit > 0, 1, 0),
cleaning_fee2 = ifelse(cleaning_fee > 0, 1, 0)) %>%
select(-security_deposit, -cleaning_fee, -square_feet)
train$security_deposit2[is.na(train$security_deposit2)] <- 0
train$cleaning_fee2[is.na(train$cleaning_fee2)] <- 0
# Make corresponding additional feature additions to scoringdata and test data
scoring <- scoring %>%
mutate(security_deposit2 = ifelse(security_deposit > 0, 1, 0),
cleaning_fee2 = ifelse(cleaning_fee > 0, 1, 0))
scoring$security_deposit2[is.na(scoring$security_deposit2)] <- 0
scoring$cleaning_fee2[is.na(scoring$cleaning_fee2)] <- 0
test <- test %>%
mutate(security_deposit2 = ifelse(security_deposit > 0, 1, 0),
cleaning_fee2 = ifelse(cleaning_fee > 0, 1, 0))
test$security_deposit2[is.na(test$security_deposit2)] <- 0
test$cleaning_fee2[is.na(test$cleaning_fee2)] <- 0
train <- train %>%
select(-host_total_listings_count, -minimum_minimum_nights, -minimum_nights, -maximum_nights,
-maximum_minimum_nights, -minimum_maximum_nights, -maximum_maximum_nights, -availability_30,
-availability_60, -availability_90, -number_of_reviews_ltm)
# mdata is a placeholder atm with just numeric variables with no NAs
mdata <- train
# Placeholder to just get numeric variables
locs <- lapply(mdata, is.numeric) %>% unlist()
mdata <- mdata[, locs] %>% select(-contains("_price"))
# Forward stepwise model
start_model <- lm(price ~ 1, mdata)
end_model <- lm(price ~ ., mdata)
model <- step(start_model,
scope = list(upper = end_model, lower = start_model),
direction = "forward",
trace = F)
summary(model)
# Lasso model
X <- model.matrix(price ~ ., mdata)
y <- mdata$price
set.seed(1431)
cv.lasso <- cv.glmnet(X, y, alpha = 1)
plot(cv.lasso)
coef(cv.lasso, s = cv.lasso$lambda.min)
pred <- predict(model2)
rmse <- mean((train$price - pred)^2) %>% sqrt()
test_pred <- predict(model2, newdata = test)
t_rmse <- mean((test$price - test_pred)^2) %>% sqrt()
paste("Training RMSE:", rmse)
paste("Test RMSE:", t_rmse)
pred <- predict(model, newdata = scoring)
submission <- data.frame(id = scoring$id, price = pred)
write_csv(submission, "../input/pricelala2/submission.csv")
pred <- predict(model)
rmse <- mean((train$price - pred)^2) %>% sqrt()
test_pred <- predict(model, newdata = test)
t_rmse <- mean((test$price - test_pred)^2) %>% sqrt()
paste("Training RMSE:", rmse)
paste("Test RMSE:", t_rmse)
pred <- predict(model, newdata = scoring)
pred
submission <- data.frame(id = scoring$id, price = pred)
head(submission)
write_csv(submission, "submission.csv")
---
title: "Predicting Airbnb Prices"
author: "Charlie Mei (cm3947)"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # metapackage with lots of helpful functions
library(leaps)
library(glmnet)
library(gridExtra)
library(caret)
library(broom)
# Import the data and create and train and test set
mydata <- read.csv("../input/pricelala2/analysisData.csv", stringsAsFactors = F)
scoring <- read.csv("../input/pricelala2/scoringData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
```
library(tidyverse) # metapackage with lots of helpful functions
library(leaps)
library(glmnet)
library(gridExtra)
library(caret)
library(broom)
# Import the data and create and train and test set
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
scoring <- read.csv("Data/scoringData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
# Density plot
p1 <- ggplot(train, aes(price)) +
geom_density(col = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = mean(mydata$price), col = "red") +
labs(title = "Distribution of prices") +
theme_minimal()
# Boxplot to identify outliers
p2 <- ggplot(train, aes(1, price)) +
geom_boxplot(col = "red", fill = "blue", alpha = 0.4) +
theme_minimal()
grid.arrange(p1, p2, ncol = 2)
# Create LB (lower bound) and UB (upper bound) to remove outliers, also remove price = 0
LB <- quantile(train$price, probs = 0.25 ) - 1.5*IQR(train$price)
UB <- quantile(train$price, probs = 0.75) + 1.5*IQR(train$price)
train <- train %>% filter(price >= LB & price <= UB, price != 0)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(leaps)
library(glmnet)
library(gridExtra)
library(caret)
library(broom)
# Import the data and create and train and test set
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
scoring <- read.csv("Data/scoringData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
warnings()
rm(list = ls())
mydata <- read.csv("Data/analysisData.csv", stringsAsFactors = F)
scoring <- read.csv("Data/scoringData.csv", stringsAsFactors = F)
set.seed(1431)
split <- createDataPartition(mydata$price, p = 0.8, list = FALSE, groups = 100)
train <- as_tibble(mydata[split, ])
test <- as_tibble(mydata[-split, ])
# Density plot
p1 <- ggplot(train, aes(price)) +
geom_density(col = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = mean(mydata$price), col = "red") +
labs(title = "Distribution of prices") +
theme_minimal()
# Boxplot to identify outliers
p2 <- ggplot(train, aes(1, price)) +
geom_boxplot(col = "red", fill = "blue", alpha = 0.4) +
theme_minimal()
grid.arrange(p1, p2, ncol = 2)
# Create LB (lower bound) and UB (upper bound) to remove outliers, also remove price = 0
LB <- quantile(train$price, probs = 0.25 ) - 1.5*IQR(train$price)
UB <- quantile(train$price, probs = 0.75) + 1.5*IQR(train$price)
train <- train %>% filter(price >= LB & price <= UB, price != 0)
# Density plot
p1 <- ggplot(train, aes(price)) +
geom_density(col = "blue", fill = "blue", alpha = 0.4) +
geom_vline(xintercept = mean(mydata$price), col = "red") +
labs(title = "Distribution of prices") +
theme_minimal()
# Boxplot to identify outliers
p2 <- ggplot(train, aes(1, price)) +
geom_boxplot(col = "red", fill = "blue", alpha = 0.4) +
theme_minimal()
grid.arrange(p1, p2, ncol = 2)
# Create LB (lower bound) and UB (upper bound) to remove outliers, also remove price = 0
LB <- quantile(train$price, probs = 0.25 ) - 1.5*IQR(train$price)
UB <- quantile(train$price, probs = 0.75) + 1.5*IQR(train$price)
train <- train %>% filter(price >= LB & price <= UB, price != 0)
# Tabularize counts of missingness
tab.missing <- function(df){
locs <- lapply(df, is.numeric) %>% unlist()
ndata <- df[, locs] %>% select(-id, -price, -weekly_price, -monthly_price)
lapply(ndata, function(x){sum(is.na(x))}) %>% unlist()
}
warnings()
tab.missing(train)
train <- train %>%
filter(!is.na(beds), !is.na(reviews_per_month), !is.na(host_listings_count), !is.na(host_total_listings_count)) %>%
mutate(security_deposit2 = ifelse(security_deposit > 0, 1, 0),
cleaning_fee2 = ifelse(cleaning_fee > 0, 1, 0)) %>%
select(-security_deposit, -cleaning_fee, -square_feet)
train$security_deposit2[is.na(train$security_deposit2)] <- 0
train$cleaning_fee2[is.na(train$cleaning_fee2)] <- 0
# Make corresponding additional feature additions to scoringdata and test data
scoring <- scoring %>%
mutate(security_deposit2 = ifelse(security_deposit > 0, 1, 0),
cleaning_fee2 = ifelse(cleaning_fee > 0, 1, 0))
scoring$security_deposit2[is.na(scoring$security_deposit2)] <- 0
scoring$cleaning_fee2[is.na(scoring$cleaning_fee2)] <- 0
test <- test %>%
mutate(security_deposit2 = ifelse(security_deposit > 0, 1, 0),
cleaning_fee2 = ifelse(cleaning_fee > 0, 1, 0))
test$security_deposit2[is.na(test$security_deposit2)] <- 0
test$cleaning_fee2[is.na(test$cleaning_fee2)] <- 0
train <- train %>%
select(-host_total_listings_count, -minimum_minimum_nights, -minimum_nights, -maximum_nights,
-maximum_minimum_nights, -minimum_maximum_nights, -maximum_maximum_nights, -availability_30,
-availability_60, -availability_90, -number_of_reviews_ltm)
# mdata is a placeholder atm with just numeric variables with no NAs
mdata <- train
# Placeholder to just get numeric variables
locs <- lapply(mdata, is.numeric) %>% unlist()
mdata <- mdata[, locs] %>% select(-contains("_price"))
# Forward stepwise model
start_model <- lm(price ~ 1, mdata)
end_model <- lm(price ~ ., mdata)
model <- step(start_model,
scope = list(upper = end_model, lower = start_model),
direction = "forward",
trace = F)
summary(model)
X <- model.matrix(price ~ ., mdata)
y <- mdata$price
set.seed(1431)
cv.lasso <- cv.glmnet(X, y, alpha = 1)
plot(cv.lasso)
coef(cv.lasso, s = cv.lasso$lambda.min)
# Calculate RMSEs
pred <- predict(model2)
pred <- predict(model)
rmse <- mean((train$price - pred)^2) %>% sqrt()
test_pred <- predict(model2, newdata = test)
test_pred <- predict(model, newdata = test)
t_rmse <- mean((test$price - test_pred)^2) %>% sqrt()
paste("Training RMSE:", rmse)
paste("Test RMSE:", t_rmse)
pred <- predict(model, newdata = scoring)
submission <- data.frame(id = scoring$id, price = pred)
write_csv(submission, "../input/pricelala2/submission.csv")
pred <- predict(model, newdata = scoring)
submission <- data.frame(id = scoring$id, price = pred)
write_csv(submission, "submission.csv")
